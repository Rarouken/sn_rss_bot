import feedparser
import requests
import hashlib
import os
import time
from transformers import pipeline

SLAVIC_COUNTRIES = [
    # Polska
    "polska", "poland", "pl", "warszawa", "warsaw", "krak√≥w", "krakow", "wroc≈Çaw", "wroclaw", "gda≈Ñsk", "gdansk", "poznan", "poznan", "lodz", "≈Ç√≥d≈∫", "szczecin", "katowice", "lubin",
    # Czechy ...
    # ... reszta jak poprzednio
]

# --- Lista RSS-√≥w ---
rss_feeds = [
    # üìå Og√≥lne ≈∫r√≥d≈Ça informacyjne
    "https://www.rmf24.pl/fakty/polska/feed",                # Polska ‚Äì RMF24
    "https://rss.onet.pl/",                                 # Polska ‚Äì Onet
    "https://gazeta.pl/rss/",                               # Polska ‚Äì Gazeta.pl

    "https://www.ceskatelevize.cz/rss/ct24.xml",            # Czechy ‚Äì ƒåT24
    "https://www.idnes.cz/rss.aspx",                        # Czechy ‚Äì iDnes.cz
    "https://rss.aktualne.cz/",                             # Czechy ‚Äì Aktu√°lnƒõ.cz

    "https://www.sme.sk/rss/",                              # S≈Çowacja ‚Äì SME.sk
    "https://spravy.pravda.sk/rss/",                        # S≈Çowacja ‚Äì Pravda.sk
    "https://www.aktuality.sk/rss/",                        # S≈Çowacja ‚Äì Aktuality.sk

    "https://meduza.io/rss/all",                            # Rosja ‚Äì Meduza
    "https://rss.ria.ru/export/rss2/world/index.xml",       # Rosja ‚Äì RIA Novosti
    "https://www.themoscowtimes.com/rss",                   # Rosja ‚Äì The Moscow Times

    "https://www.pravda.com.ua/rss",                        # Ukraina ‚Äì Ukrainska Pravda
    "https://kyivindependent.com/feed",                     # Ukraina ‚Äì Kyiv Independent
    "https://www.kyivpost.com/rss/site.xml",                # Ukraina ‚Äì Kyiv Post
    "https://www.radiosvoboda.org/api/feeds",               # Ukraina ‚Äì Radio Svoboda

    "https://nashaniva.com/ru/rss/",                        # Bia≈Çoru≈õ ‚Äì Nasha Niva
    "https://www.rferl.org/api/feeds?region=Belarus",       # Bia≈Çoru≈õ ‚Äì Radio Svoboda

    "https://www.rts.rs/rss/ci.xml",                        # Serbia ‚Äì RTS
    "https://www.blic.rs/rss",                              # Serbia ‚Äì Blic
    "https://www.danas.rs/feed/",                           # Serbia ‚Äì Danas

    "https://www.hrt.hr/feeds/",                            # Chorwacja ‚Äì HRT
    "https://www.index.hr/rss/",                            # Chorwacja ‚Äì Index.hr
    "https://www.jutarnji.hr/rss",                          # Chorwacja ‚Äì Jutarnji list

    "https://balkaninsight.com/feed/",                      # Bo≈õnia i Hercegowina ‚Äì BIRN BiH
    "https://cin.ba/feed/",                                 # Bo≈õnia i Hercegowina ‚Äì CIN
    "https://ba.n1info.com/rss/",                           # Bo≈õnia i Hercegowina ‚Äì N1 BiH

    "https://www.vijesti.me/rss",                           # Czarnog√≥ra ‚Äì Vijesti
    "https://www.raskrinkavanje.me/rss",                    # Czarnog√≥ra ‚Äì Raskrinkavanje

    "https://kallxo.com/feed/",                             # Kosowo ‚Äì Kallxo
    "https://www.koha.net/rss",                             # Kosowo ‚Äì Koha Ditore

    "https://meta.mk/feed/",                                # Macedonia P√≥≈Çnocna ‚Äì Meta.mk
    "https://www.slobodenpecat.mk/feed/",                   # Macedonia P√≥≈Çnocna ‚Äì Sloboden Pechat

    "https://btvnovinite.bg/rss",                           # Bu≈Çgaria ‚Äì BTV News
    "https://nova.bg/news/rss",                             # Bu≈Çgaria ‚Äì Nova TV
    "https://www.dnevnik.bg/rss.php",                       # Bu≈Çgaria ‚Äì Dnevnik.bg

    "https://www.rtvslo.si/rss/",                           # S≈Çowenia ‚Äì RTV Slovenija
    "https://www.delo.si/rss/",                             # S≈Çowenia ‚Äì Delo
    "https://podcrto.si/feed/",                             # S≈Çowenia ‚Äì Pod ƒçrto

    # üíº Sekcje ekonomiczne
    "https://www.pb.pl/rss",                                # Polska ‚Äì Puls Biznesu :contentReference[oaicite:1]{index=1}

    "https://hn.ihned.cz/rss",                              # Czechy ‚Äì Hospod√°≈ôsk√© noviny

    "https://www.hnonline.sk/rss",                          # S≈Çowacja ‚Äì Hospod√°rske noviny

    "https://www.vedomosti.ru/rss/news.xml",                # Rosja ‚Äì Vedomosti

    "https://www.interfax.com.ua/ua/rss/business/",         # Ukraina ‚Äì Interfax-Ukraine Business

    # Bia≈Çoru≈õ ‚Äì brak RSS specyficznego, mo≈ºna siƒôgnƒÖƒá po emigracyjne
    "https://bizlife.rs/feed/",                             # Serbia ‚Äì BizLife.rs

    "https://www.poslovni.hr/rss",                          # Chorwacja ‚Äì Poslovni dnevnik

    "https://cin.ba/feed/",                                 # Bo≈õnia i Hercegowina ‚Äì CIN (sekcja tak≈ºe ekonomiczna)

    "https://www.vijesti.me/rss/business",                  # Czarnog√≥ra ‚Äì Vijesti Business

    "https://biznes.koha.net/rss",                          # Kosowo ‚Äì Koha Biznes

    "https://meta.mk/feed/",                                # Macedonia P√≥≈Çnocna ‚Äì Meta.mk (analizy ekonomiczne)

    "https://www.capital.bg/rss",                           # Bu≈Çgaria ‚Äì Capital.bg :contentReference[oaicite:2]{index=2}

    "https://www.monitor.si/rss/",                          # S≈Çowenia ‚Äì Monitor.si

    "https://www.imf.org/external/index.xml"                # Globalnie ‚Äì IMF Publications
]


DISCORD_WEBHOOK = "https://discordapp.com/api/webhooks/1392262052742959155/DEQ5zlgo3bdqzFkrLX1OyxyvybmRLnVNqcAQjeDVwt8FtUeXhCodvR6UuUILBdAUGvQi"  # <- tu wklej sw√≥j

LT_ENDPOINTS = [
    "https://libretranslate.com/translate",
    "https://translate.astian.org/translate",
    "https://libretranslate.de/translate",
    "https://translate.argosopentech.com/translate"
]

from googletrans import Translator as GoogleTranslator
google_translator = GoogleTranslator()

def translate_to_english(text):
    MAX_CHARS = 3500
    if len(text) > MAX_CHARS:
        text = text[:MAX_CHARS].rsplit(" ", 1)[0] + "..."
    for url in LT_ENDPOINTS:
        try:
            payload = {
                "q": text,
                "source": "auto",
                "target": "en",
                "format": "text"
            }
            response = requests.post(url, data=payload, timeout=15)
            if response.ok:
                data = response.json()
                translated = data.get("translatedText", "").strip()
                if translated and translated.lower() != text.lower() and len(translated) > 15:
                    return translated
        except Exception:
            continue
    try:
        translated = google_translator.translate(text, dest='en').text
        if translated and translated.lower() != text.lower():
            return f"[Google Fallback] {translated}"
    except Exception:
        pass
    first_line = text.split('\n', 1)[0].strip()
    return f"[Translation failed]\nOriginal headline:\n{first_line}"

# --- ML klasyfikacja ---
hf_classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

TOPIC_LABELS = [
    "polityka krajowa", "polityka zagraniczna", "gospodarka", "historia", "kultura", "spo≈Çecze≈Ñstwo",
    "bezpiecze≈Ñstwo", "wojna", "dyplomacja", "to≈ºsamo≈õƒá narodowa", "media", "integracja s≈Çowia≈Ñska",
    "stosunki miƒôdzynarodowe", "konflikty", "prawo", "samorzƒÖd", "organizacje miƒôdzynarodowe"
]

def classify_topic(text):
    result = hf_classifier(text, TOPIC_LABELS)
    top_label = result["labels"][0]
    top_score = result["scores"][0]
    print(f"[CLASSIFY] ‚Üí {top_label} ({top_score:.2f}) for text: {text[:80]}")
    if top_score >= 0.6:
        return top_label
    return None

def contains_slavic_country(text, tags, source):
    for root in SLAVIC_COUNTRIES:
        if root in text:
            return True
        if any(root in tag.lower() for tag in tags):
            return True
        if root in source.lower():
            return True
    return False

# --- Antyduplikaty ---
ARTICLE_TTL_SECONDS = 3 * 24 * 3600
SENT_ARTICLES_FILE = "sent_articles.txt"

def get_article_id(entry):
    unique_string = (entry.title + entry.link).encode("utf-8")
    return hashlib.md5(unique_string).hexdigest()

def was_sent(article_id):
    if not os.path.exists(SENT_ARTICLES_FILE):
        return False
    valid_lines = []
    now = time.time()
    found = False
    with open(SENT_ARTICLES_FILE, "r") as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) != 2:
                continue
            existing_id, timestamp = parts
            try:
                timestamp = float(timestamp)
            except ValueError:
                continue
            if now - timestamp < ARTICLE_TTL_SECONDS:
                valid_lines.append(f"{existing_id} {int(timestamp)}")
                if existing_id == article_id:
                    found = True
    with open(SENT_ARTICLES_FILE, "w") as f:
        f.write("\n".join(valid_lines) + "\n")
    return found

def mark_as_sent(article_id):
    with open(SENT_ARTICLES_FILE, "a") as f:
        f.write(f"{article_id} {int(time.time())}\n")

# --- Wysy≈Çka do Discorda ---
def send_to_discord(title, link, summary=None, topic=None):
    original = f"**{title}**\n{link}\n{summary or ''}"
    to_translate = f"{title}\n{summary or ''}"
    translated = translate_to_english(to_translate)
    topic_label = f"[**{topic.upper()}**]\n" if topic else ""
    content = (
        f"{topic_label}"
        f"**Orygina≈Ç:**\n{original}\n\n"
        f"**üá¨üáß T≈Çumaczenie:**\n{translated}"
    )
    data = {"content": content}
    try:
        requests.post(DISCORD_WEBHOOK, json=data)
    except Exception as e:
        print(f"B≈ÇƒÖd Discord webhook: {e}")

# --- G≈Ç√≥wna pƒôtla ---
def fetch_and_filter():
    for feed_url in rss_feeds:
        feed = feedparser.parse(feed_url)
        for entry in feed.entries:
            article_id = get_article_id(entry)
            if was_sent(article_id):
                continue
            text = f"{entry.title} {entry.get('summary', '')}".lower()
            tags = [tag['term'] for tag in entry.get("tags", []) if 'term' in tag]
            source = entry.get("source", {}).get("title", "") or feed_url

            print("Tytu≈Ç:", entry.title)
            print("Summary:", entry.get("summary", ""))
            print("Tags:", tags)
            print("Source:", source)
            
            topic = classify_topic(text)
            if not topic:
                print("ODRZUCONE: brak klasyfikacji tematycznej przez ML")
                continue
            if not contains_slavic_country(text, tags, source):
                print("ODRZUCONE: contains_slavic_country (brak kraju/miasta S≈Çowian)")
                continue

            print("‚Üí WYSLANO!")
            send_to_discord(entry.title, entry.link, entry.get("summary", ""), topic)
            mark_as_sent(article_id)
            
if __name__ == "__main__":
    fetch_and_filter()
